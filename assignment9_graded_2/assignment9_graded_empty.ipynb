{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/logo.png\" style=\"width: 100px;\"/>\n",
    "<h1><center>Assignment 9</center></h1>\n",
    "<h3><center>Second graded assignment</center></h3>\n",
    "\n",
    "<center>Due: 11.02.2022 at 23:59</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to upload:\n",
    "\n",
    "Upload your solution via the VC course. Please upload **one Zip archive** per group. The Zip must contain:\n",
    "* Your solution **notebook** (a **.ipynb** file)\n",
    "* A **data folder** with the datasets (you probably don't have to change anything here)\n",
    "\n",
    "Your Zip should be named after the following scheme:\n",
    "\n",
    "* \"**yourname**\"\\_assignment\\_\"**number**\"\\_submission.zip\n",
    "\n",
    "\n",
    "### Please use coding comments!!!\n",
    "### 50 Points in total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) Preprocessing (15 points)\n",
    "\n",
    "A very big part of a data scientist's work is analysing and preprocessing data to be able to fit models on it. Since we haven't done this intensively in the past, we will focus on teaching you some core competences in the upcoming task. Be aware: This is just the tip of the iceberg! There are many more methods out there to preprocess data and every data set needs own bouquet of preprocessing methods.\n",
    "\n",
    "This time we'll look at data on forest fires in a region of Portugal. Source: https://archive.ics.uci.edu/ml/datasets/Forest+Fires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 1 (1 point):__ Your first task is to go to the source website and have a look at it. On the website you can find a definition of the attributes. Briefly explain what the values of X, Y and area stand for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*\n",
    "1. X - x-axis spatial coordinate within the Montesinho park map: 1 to 9\n",
    "2. Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9\n",
    "3. area - the burned area of the forest (in ha): 0.00 to 1090.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2 (5 points):__ Let's do some data anaylsis. You are free to experiment here to get the best overview of the data. Make yourself familiar with it. Make sure to cover at least the following aspects:\n",
    "* Import the data set \"forestfires.csv\" from the data folder and call it `data`\n",
    "* Have a first look at the data and display it in the print out\n",
    "* Use some methods to get an overview over the numerical data (something like a min, max, median etc. for every column would be nice)\n",
    "* Re-encode the \"area\" variable in a binary way (0/1) such that you have a variable \"fire\" in the end which states whether there was a fire or not\n",
    "* Is your data set balanced? You can find this out by calculating the proportion of observations with (without) fires\n",
    "* To get an even better overview of the data generate a pairplot (library seaborn) like in assignment 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(517, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>fire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X  Y month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  area  fire\n",
       "0  7  5   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0   0.0     0\n",
       "1  7  4   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0   0.0     0\n",
       "2  7  4   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0   0.0     0\n",
       "3  8  6   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2   0.0     0\n",
       "4  8  6   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0   0.0     0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = pd.read_csv(\"data/forestfires.csv\")\n",
    "\n",
    "#print and show data\n",
    "print(data.shape)\n",
    "data.head()\n",
    "\n",
    "#min, max, [median = 50%]\n",
    "df = pd.DataFrame(data)\n",
    "df.describe()\n",
    "\n",
    "#re-encode area in fire column\n",
    "df['fire'] = np.where(df['area']!= 0.0, 1, 0)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 3 (3 points):__ Let's create a heatmap. Heatmaps are a powerful tool to visualize three dimensional numerical data so that you can get a very quick overview. We now want to know in which areas of Portugal we had the most recorded forest fires. For this task you will use the seaborn function \"heatmap\". These steps might help you:\n",
    "* group the data by the variables X and Y\n",
    "* sum up the values of \"fire\" by the groups (*Hint: resetting the index and giving it a name helps*)\n",
    "* Your table now should have three columns [\"X\",\"Y\",\"name of sum e.g. counts\"]\n",
    "* transform this table via the function \"pivot()\"\n",
    "* Use seaborn.heatmap() to plot the heatmap; look at the documentation to find parameters which will make the heatmap look pleasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 4 (1 point):__ Do you get a good idea of the fire distribution by only looking at the counts? Explain briefly why or why not. If not, what value should you rather plot in a heatmap?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code and answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 5 (2 points):__ If your main goal will be to predict whether an area suffered from forest fires or not by using KNN, why would you want to re-encode the \"month\" and the \"day\" variable? In what way would you propose to re-encode them? Please write a function to apply your idea for the \"month\" variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code and answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now drop the \"day\" column and then split the data into x_data and y_data. If your data is still called \"data\" you can use the code below otherwise please modify to your variable names.     \n",
    "After that we rescale all our x_data with the MinMaxScaler from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = data.drop(columns = [\"fire\",\"day\"])\n",
    "y_data = data[\"fire\"]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "x_data[x_data.columns] = scaler.fit_transform(x_data)\n",
    "\n",
    "x_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 6 (1 point):__ What is the difference beteween the MinMaxScaler and StandardScaler? Why did we use the former here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your solution here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 7 (2 points):__ Apply a KNN classification with `k`=100, `weights` = \"distance\" and a 5-fold cross validation to the dataset. Use `KNeighborsClassifier` and `cross_val_score` from sklearn for this.\n",
    "Evaluate the accuracy scores. Would you say that KNN is a suitable algorithm to predict forest fires on this data set?\n",
    "\n",
    "*Hint: The given parameters to run the KNN on are one of the best parameter combinations we found.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code and answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task B) KNN and Cross Validation (16 points)\n",
    "\n",
    "Now we want you to apply another dataset to KNN. The Breast-Cancer dataset is already preprocessed, so you can start right away. Its target variable splits into \"1\" persons having breast cancer and \"0\" persons not having breast cancer. Here is a glimpse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.708333</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.481132</td>\n",
       "      <td>0.244292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.603053</td>\n",
       "      <td>0</td>\n",
       "      <td>0.370968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.283105</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.885496</td>\n",
       "      <td>0</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.562500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.251142</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.816794</td>\n",
       "      <td>0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.520548</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.702290</td>\n",
       "      <td>1</td>\n",
       "      <td>0.096774</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.583333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.150685</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.587786</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.562500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.383562</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625954</td>\n",
       "      <td>0</td>\n",
       "      <td>0.209677</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  sex        cp  trestbps      chol  fbs  restecg   thalach  exang  \\\n",
       "0  0.708333    0  1.000000  0.481132  0.244292    1        0  0.603053      0   \n",
       "1  0.166667    0  0.666667  0.339623  0.283105    0        1  0.885496      0   \n",
       "2  0.250000    1  0.333333  0.339623  0.178082    0        0  0.770992      0   \n",
       "3  0.562500    0  0.333333  0.245283  0.251142    0        1  0.816794      0   \n",
       "4  0.583333    1  0.000000  0.245283  0.520548    0        1  0.702290      1   \n",
       "5  0.583333    0  0.000000  0.433962  0.150685    0        1  0.587786      0   \n",
       "6  0.562500    1  0.333333  0.433962  0.383562    0        0  0.625954      0   \n",
       "\n",
       "    oldpeak  slope   ca  target  \n",
       "0  0.370968    0.0  0.0       1  \n",
       "1  0.564516    0.0  0.0       1  \n",
       "2  0.225806    1.0  0.0       1  \n",
       "3  0.129032    1.0  0.0       1  \n",
       "4  0.096774    1.0  0.0       1  \n",
       "5  0.064516    0.5  0.0       1  \n",
       "6  0.209677    0.5  0.0       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# from html import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # for data visualiztions\n",
    "\n",
    "data = pd.read_csv(\"data/breast_cancer_pre.csv\")\n",
    "# display(HTML(\"<h3>Breast Cancer Pre-Processed:</h3>\"))\n",
    "display(data.head(7))\n",
    "print(data.shape)\n",
    "sns.countplot(x=\"target\", data = data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = data.drop(columns=\"target\")\n",
    "y_data = data[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 1 (1 point):__ Split the data into train and test set with a `test_size` of 0.2 and a `random_state` of 42. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2 (2 points):__ You have already used k-fold cross validation in the last task. Explain what it does, and why we use it. What does it return, and how can you interpret the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-fold cross validation:\n",
    "\n",
    "The original sample is randomly partitioned into k subsets or folds of equal size. Of the k subsets, a single subset is retained as the validation data for testing the model, and the remaining k − 1 subsets are used as training data. The cross-validation process is then repeated k times, with each of the k subsamples used exactly once as the validation data.\n",
    "\n",
    "Why we use k-fold cross validation?\n",
    "\n",
    "We use it for evaluating a model’s performance and for hyperparameter tuning\n",
    "\n",
    "\n",
    "What does k-fold cross validation return, and how can you interpret the results?\n",
    "\n",
    "This provides k measures of predictive performance, and we can then analyze their mean and standard deviation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 3 (4 points):__ We want to train a KNN classifier for the given data. But we do not know how to set the hyperparameters. Your task now is to perform a *grid search* to find optimal values for `k` and `weights`. For `k`, consider every value in the the range $ [1, 25] $, and for `weights` consider the values `\"uniform\"` and `\"distance\"`. For each possible hyperperameter combination, perform a k-fold cross validation with 10 folds. Select one hyperparameter setting you determine to be best, and explain why you think this is the best one.\n",
    "\n",
    "**Note:** There is a function in sklearn that automatically performs a grid search for you. **Please do not use this**, but implement the grid search yourself. You can, however, use the sklearn implementation for k-fold-cross-validation and for the KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=4, weight=distance\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import operator\n",
    "\n",
    "#For k, considering every value in the the range  [1,25]\n",
    "n_neighbors = list(range(1, 26))\n",
    "\n",
    "#for weights considering the values \"uniform\" and \"distance\"\n",
    "weights = ['uniform','distance']\n",
    "\n",
    "n_neighbors = list(range(1, 26))\n",
    "weights = ['uniform','distance']\n",
    "avg_scores = {}\n",
    "for k in n_neighbors:\n",
    "    for weight in weights:\n",
    "        knn = KNeighborsClassifier(n_neighbors = k, weights = weight)\n",
    "        scores = cross_val_score(knn, x_data, y_data, cv=10)\n",
    "        #taking mean score of the cross_val_score in a dictionary\n",
    "        avg_scores[\"k=\"+str(k)+\", weight=\"+weight] = scores.mean()\n",
    "\n",
    "#getting maximum score from the dictionary\n",
    "print(max(avg_scores.items(), key=operator.itemgetter(1))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use k = `4` and weight as `\"distance\"` becaue we performed a grid search to find optimal values for k and weights. Here we used k-fold cross validation and this one hyperparameter has the highest score.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 4 (1 point):__ Explain the difference between `uniform` and `distance` weights in the context of KNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`uniform` assigns no weight, while `distance` weighs points by the inverse of their distances meaning nearer points will have more weight than the farther points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 5 (1 point):__ Now train your final model with KNN using the best hyperparameters you found in Task 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4, weights='distance')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 4, weights = 'distance')\n",
    "\n",
    "# 2. Train (Fit) the KNN classifier with our training data\n",
    "knn.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 6 (2 points):__ Evaluate your model against the test set. Print out the accuracy and interpret it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8360655737704918\n",
      "\n",
      "                      Ground Truth   \n",
      "          |         |Positive |Negative |\n",
      "Prediction|Positive |   24    |    2    |\n",
      "          |Negative |    8    |   27    |\n"
     ]
    }
   ],
   "source": [
    "# Evaluating model against the test set\n",
    "y_pred = knn.predict(x_test)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "# Displaying the confusion matrix\n",
    "print()\n",
    "print(\"{:<19}{:^18}\".format('', 'Ground Truth'))\n",
    "print(\"{:<10}|{:^9}|{:^9}|{:^9}|\".format('', '', 'Positive', 'Negative'))\n",
    "print(\"{:<10}|{:<9}|{:^9}|{:^9}|\".format('Prediction', 'Positive', tp, fp))\n",
    "print(\"{:<10}|{:<9}|{:^9}|{:^9}|\".format('', 'Negative', fn, tn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 7 (1 points):__ Explain the residual in terms of KNN. What is it? How to calculate it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual is the error $\\hat f(x) − f (x)$ in approximating the target function. Nearest neighbor approaches can be thought of as approximating the target function at the single query point $x_{q}$. The distance between this target function and the measerd values scattered around this target function is residual.\n",
    "\n",
    "It can be calculated using $\\hat f(x) − f (x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 8 (1 point):__ What does \"curse of dimensionality\" in the context of KNN mean? How can you solve the problem when working with KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Curse of Dimensionality\" in the context of KNN:\n",
    "\n",
    "The KNN algorithm hinges on data points being close together. This becomes challenging as the number of dimensions increases, referred to as the “Curse of Dimensionality.” It’s especially hard for the KNN algorithm it requires two points to be very close on every axis, and adding a new dimension creates another opportunity for points to be farther apart. As the number of dimensions increases, the closest distance between two points approaches the average distance between points, eradicating the ability of the k-nearest neighbors algorithm to provide valuable predictions.\n",
    "\n",
    "Solution of the \"Curse of Dimensionality\" when working with KNN:\n",
    "\n",
    "To overcome this challenge, we can add more data to the data set. By doing so we add density to the data space, bringing the nearest points closer together and returning the ability of the KNN algorithm to provide valuable predictions. This is a valuable solution so long as we have the hardware needed to perform computations on our data set. As our data set gets larger and larger, we need more and more computing power to process it. Eventually the size of our data set will surpass our computing power. At that point, we need to use dimensionality reduction to present all of the valuable information in fewer dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 9 (3 points):__ Think of all the machine learning models that you've learned during the semester. Which one would also be fit for this type of data? Name the model and explain why you would choose exactly this one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary classification refers to those classification tasks that have two class labels. The breast cancer dataset has two class, \"1\" persons having breast cancer and \"0\" persons not having breast cancer.\n",
    "\n",
    "Typically, binary classification tasks involve one class that is the normal state and another class that is the abnormal state. It is common to model a binary classification task with a model that predicts a Bernoulli probability distribution for each example.\n",
    "\n",
    "The Bernoulli distribution is a discrete probability distribution that covers a case where an event will have a binary outcome as either a 0 or 1. For classification, this means that the model predicts a probability of an example belonging to class 0, or the abnormal state 1.\n",
    "\n",
    "The algorithm that will also fit this type of data:\n",
    "\n",
    "    2. Decision Trees\n",
    "    3. Support Vector Machines\n",
    "    4. Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task C) Reinforcement Learning in the Wumpus World (19 points)\n",
    "\n",
    "The Wumpus world is a traditional toy domain to test intelligent agents. The world consists of a 2D grid where each cell contains at most one token. There are empty cells (denoted as 'E'), pits ('P'), the evil Wumpus ('W') and a pot of gold ('G'). An agent ('A') has to find its way through the Wumpus world and ideally reach the gold. The agent can only move to horizontally or vertically adjacent cells (not diagonally). If the agent enters a cell with either the Wumpus or a pit, it dies. So long story short: Gold good, pits and Wumpus bad.\n",
    "\n",
    "We want to find an ideal strategy for an agent that is placed at a random starting cell in the Wumpus world. We will accomplish this with reinforcement learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first import useful libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # for the arrays\n",
    "from time import sleep # for controlling the speed of animations\n",
    "import wumpus_utils as wu # some utility functions that might come in handy. You will have to install the package 'ipycanvas' with the guide given here: https://ipycanvas.readthedocs.io/en/latest/installation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code snipped creates a fresh Wumpus world $M$ with the tokens explained above. Notice that there is no agent at the beginning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the wumpus world (no agent at the beginning)\n",
    "world = [[\"E\", \"E\", \"P\", \"E\"],\n",
    "         [\"W\", \"E\", \"G\", \"E\"],\n",
    "         [\"E\", \"E\", \"E\", \"P\"],\n",
    "         [\"E\", \"P\", \"E\", \"E\"]]\n",
    "world = np.array(world)\n",
    "\n",
    "# for cleaner reference, get the number of rows and columns of our world:\n",
    "num_rows = world.shape[0]\n",
    "num_cols = world.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to have a visual reference of the current state of the world. The *wumpus_utils* provide a nice functionality for that. The function *draw_world(wumpus_world, agent_pos=None)* draws the current world behind the scenes given a world in the style of above. An optional *agent_pos* in the form of a list __[agent_row, agent_col]__ can also later draw a world with the agent included. The function *display_world()* finally displays the drawn world in the notebook. Keep in mind, that once you display the world with *display_world()*, all other calls of *display_world()* will just spawn a clone of the underlying canvas at the place in the notebook you executed the call. So it is sufficient to call *display_world* only once at one place in the notebook and this display will then be changed if you redraw the world. If you decide to have multiple displays, then all clones will be altered synchronously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88562889311451db041bc83224a57c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RoughCanvas(height=200, width=200)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wu.draw_world(world)\n",
    "wu.display_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to establish the rewards that an agent should receive if it enters a cell with a particular token. The reward dictionary given below indicates the rewards for each token $t$ (e.g. $reward(t==P) = -1000$).\n",
    "\n",
    "We are only interested in the token the agent finds when it enters into a cell (not where the agent came from). This means, we can establish a reward matrix $R$ that has the same size as the world and where $R_{rc} = reward(M_{rc})$.\n",
    "\n",
    "__Task 1 (3 points):__ Fill the reward matrix by respecting the world $M$ given above and the reward dictionary given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   -1    -1 -1000    -1]\n",
      " [-1000    -1  1000    -1]\n",
      " [   -1    -1    -1 -1000]\n",
      " [   -1 -1000    -1    -1]]\n"
     ]
    }
   ],
   "source": [
    "reward_dict = { # the expected reward when finding the respective token\n",
    "    \"E\": -1,\n",
    "    \"P\": -1000,\n",
    "    \"W\": -1000,\n",
    "    \"G\": 1000\n",
    "}\n",
    "\n",
    "reward_matrix = np.zeros(shape=(num_rows, num_cols), dtype=np.int16) # our rewards will always be integers\n",
    "\n",
    "####################\n",
    "# TODO implement here\n",
    "for idx, x in np.ndenumerate(world):\n",
    "    reward_matrix[idx] = reward_dict[x]  \n",
    "####################\n",
    "      \n",
    "print(reward_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2 (1 point):__ What could be the rationale behind giving a reward of '-1' every time the agent enters an empty cell?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your solution here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we of course want to apply Q-learning to our world. First, some hyperparameters and the initialized Q-value-matrix (all zeros) is given. The Q-value-matrix is designed as follows: For each possible action in the world a value is saved. A possible action from the agent can be going either north, east, south or west (in our implementation, if it is not possible to go in a particular direction (border cells), the respective value just stays zero). The first two dimensions of the matrix is the position of the agent. The last dimension is the direction of the move (index 0 = north, index 1 = east, index 2 = south, index 3 = west). If e.g. there is a value of 42 at *q_value_matrix[2][3][0]*, that means that the q-value of the action of being at row 2, column 3 and going north is 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.8 # the decay paramater\n",
    "num_episodes = 100 # the number of episodes\n",
    "pause_val = 0.01 # the time in seconds that is used as a pause between frames for the animation\n",
    "q_value_matrix = np.zeros(shape=(num_rows, num_cols, 4), dtype=np.int16) # the Q-value-matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 3 (10 points):__ Below you find a stub for simulating multiple episodes of an agent walking through the world. Do not change existing code lines or their order! Your job is to implement the Q-learning algorithm that you have learned in the lecture and practice to find Q-values for all possible actions. We use the *draw_world* feature explained above to always show the current situation. You can either duplicate the display of the world again here or have a look at the changing world drawn above.\n",
    "\n",
    "Use the stub below to implement the algorithm from the lecture to find the q-values. Train for the number of episodes stated above with the given gamma value. Make sure that your agent does not randomly walk out of the world. You can make *pause_val* smaller for faster animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wu.display_world()\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    print(\"Start of episode\", episode)\n",
    "    \n",
    "    # let us place the agent randomly in the world such that it does not start in an unempty cell\n",
    "    agent_pos = [np.random.randint(num_rows), np.random.randint(num_cols)] # the position of the agent represented as a list [row, column]\n",
    "    while not world[agent_pos[0]][agent_pos[1]] == \"E\": # find a new position for the agent as long as it is not placed in an empty cell\n",
    "        agent_pos = [np.random.randint(num_rows), np.random.randint(num_cols)]\n",
    "    \n",
    "    # draw the initial world with the agent\n",
    "    wu.draw_world(world, agent_pos)\n",
    "    # Hold the execution for a given amount of seconds\n",
    "    sleep(pause_val)\n",
    "    \n",
    "    goal_reached = False\n",
    "    while not goal_reached: # while the agent has not stepped in an unempty cell\n",
    "        \n",
    "        ####################\n",
    "        # TODO implement updating your q-value-matrix here\n",
    "        ####################\n",
    "        \n",
    "        if not world[agent_pos[0]][agent_pos[1]] == \"E\": # End the current episode if the agent has stepped in an unempty cell\n",
    "            goal_reached = True\n",
    "        \n",
    "        # draw the current situation and wait for a given amount in seconds.\n",
    "        wu.draw_world(world, agent_pos)\n",
    "        sleep(pause_val)\n",
    "\n",
    "print(q_value_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 4 (3 points)__ You now have trained strategies for your agent, such that it knows where to go next in each cell. Now implement the following function *follow_strategy(agent_pos)* that takes the position of an agent in [row,col] fashion and executes the learned strategy until a goal is reached. Again do not change existing code lines or their order!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pause_val = 1 # make the animation a bit slower\n",
    "\n",
    "def follow_strategy(agent_pos):\n",
    "    if not world[agent_pos[0]][agent_pos[1]] == \"E\": # check if the agent started on a non-empty cell\n",
    "        return\n",
    "    \n",
    "    goal_reached = False\n",
    "    while not goal_reached:\n",
    "        \n",
    "        ####################\n",
    "        # TODO implement here\n",
    "        ####################\n",
    "        \n",
    "        if not world[agent_pos[0]][agent_pos[1]] == \"E\":\n",
    "            goal_reached = True\n",
    "\n",
    "        wu.draw_world(world, agent_pos)\n",
    "        sleep(pause_val)\n",
    "\n",
    "agent_pos = [1, 0]\n",
    "wu.draw_world(world, agent_pos=agent_pos)\n",
    "wu.display_world()\n",
    "sleep(pause_val)\n",
    "follow_strategy(agent_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 5 (2 points):__ Shortly describe in your own words what the impact of either a small or big gamma value would be on your learning of the Wumpus world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your solution here*"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
